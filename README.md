# Data-Bias
I examined the bias in a natural language processing model, the API Perspective tool by Google Jigsaw, by seeing how accurately the model rated comments. The 

The API Prespective tool rates comments based on their toxicites with categories of the following: "toxic," "severe_toxic," "obscene," "threat," "insult," and "identity_hate." The comments were a aprt of a dataset of Wikipedia. For my purposes, I focused specifically on the "toxic" and "severe toxic" comments. My goal was to find a threshold where the comments become "toxic" and "severely toxic" while also seeing where the percentage of false negetive results which indicate the model's biases. In order to do this, I came up with a list of possible threshold values and made pie charts of each toxicty score. I also incuded percnetages that woulc clearly show what the false negetivity rate when the score is aboce a given toxicity score. My results were that as the toxicty score increased, the likelihood for a false negetive decreased, this was consistent with my hypothesis that after a certain threshold value, the "not toxic" rates would cease. 
I believe there are definetly biases in this model, like any other model. I believe the data behind the creation of the model is crutial because it can significantly alter the accuracy of the model. In addition to the orginal comments from the Wikipedia dataset, I tested the model with my own comments to see how the scores would differ. I found consistent results with the previous testing of the dataset. Depending on how well the model was trained and with both the quality and quantity of the data, I would have a better sense of why my results are the way they are. With that said, the model was able to give results that were close to the target values. This brings me to my question: Is it possible to eliminate data bias altogether? What are some of the reprocussions we have to face with current data bias that exists in technologies in our everyday lives? 
